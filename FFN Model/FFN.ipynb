{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ7hSpb7MfIu",
        "outputId": "0d70c487-0e1a-4474-f274-cdec2df5812c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8337/8337 [==============================] - 22s 3ms/step - loss: 0.7994 - accuracy: 0.6982 - val_loss: 0.7101 - val_accuracy: 0.7272\n",
            "Epoch 2/10\n",
            "8337/8337 [==============================] - 21s 2ms/step - loss: 0.6820 - accuracy: 0.7387 - val_loss: 0.6901 - val_accuracy: 0.7339\n",
            "Epoch 3/10\n",
            "8337/8337 [==============================] - 23s 3ms/step - loss: 0.6441 - accuracy: 0.7524 - val_loss: 0.6413 - val_accuracy: 0.7514\n",
            "Epoch 4/10\n",
            "8337/8337 [==============================] - 22s 3ms/step - loss: 0.6226 - accuracy: 0.7602 - val_loss: 0.6335 - val_accuracy: 0.7548\n",
            "Epoch 5/10\n",
            "8337/8337 [==============================] - 19s 2ms/step - loss: 0.6072 - accuracy: 0.7655 - val_loss: 0.6213 - val_accuracy: 0.7603\n",
            "Epoch 6/10\n",
            "8337/8337 [==============================] - 23s 3ms/step - loss: 0.5954 - accuracy: 0.7703 - val_loss: 0.6098 - val_accuracy: 0.7631\n",
            "Epoch 7/10\n",
            "8337/8337 [==============================] - 21s 2ms/step - loss: 0.5866 - accuracy: 0.7731 - val_loss: 0.6010 - val_accuracy: 0.7670\n",
            "Epoch 8/10\n",
            "8337/8337 [==============================] - 21s 3ms/step - loss: 0.5786 - accuracy: 0.7755 - val_loss: 0.6001 - val_accuracy: 0.7669\n",
            "Epoch 9/10\n",
            "8337/8337 [==============================] - 23s 3ms/step - loss: 0.5720 - accuracy: 0.7790 - val_loss: 0.5948 - val_accuracy: 0.7701\n",
            "Epoch 10/10\n",
            "8337/8337 [==============================] - 20s 2ms/step - loss: 0.5666 - accuracy: 0.7801 - val_loss: 0.6021 - val_accuracy: 0.7673\n",
            "2606/2606 [==============================] - 5s 2ms/step - loss: 0.6025 - accuracy: 0.7659\n",
            "Test Loss: 0.6024633049964905\n",
            "Test Accuracy: 0.765888512134552\n",
            "2606/2606 [==============================] - 4s 1ms/step\n",
            "2606/2606 [==============================] - 4s 1ms/step - loss: 0.6025 - accuracy: 0.7659\n",
            "Precision: 0.7637832722900731\n",
            "Recall: 0.7658885343441856\n",
            "F1-score: 0.7634821096843183\n",
            "Test Loss: 0.6024633049964905\n",
            "Test Accuracy: 0.765888512134552\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(r\"/content/emotions.csv\")\n",
        "\n",
        "# Data preprocessing\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "\n",
        "# Tokenization and stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_and_tokenize(text):\n",
        "    return [word for word in text.split() if word.lower() not in stop_words]\n",
        "\n",
        "X_tokenized = X.apply(clean_and_tokenize)\n",
        "\n",
        "# Train Word2Vec model\n",
        "model_Word2Vec = Word2Vec(sentences=X_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to create sentence vectors by averaging word vectors\n",
        "def sentence_vector(sentence):\n",
        "    vectors = [model_Word2Vec.wv[word] for word in sentence if word in model_Word2Vec.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model_Word2Vec.vector_size)\n",
        "\n",
        "# Convert text data to fixed-length vectors\n",
        "X_features = np.array([sentence_vector(sentence) for sentence in X_tokenized])\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(data['label'].unique())\n",
        "y_encoded = pd.get_dummies(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Predict labels\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(np.array(y_test), axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "model.save(\"emotions_ffn.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"emotions_ffn.keras\")"
      ],
      "metadata": {
        "id": "uSspyAMPPCyV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/emotions_ffn.keras')"
      ],
      "metadata": {
        "id": "5ItlfNqiRe6T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1tS-HaoRzma",
        "outputId": "9f85dcc5-3f70-4b00-a39b-6932e6b08532"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2606/2606 [==============================] - 7s 2ms/step - loss: 0.6025 - accuracy: 0.7659\n",
            "Test Loss: 0.6024633049964905\n",
            "Test Accuracy: 0.765888512134552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFq5Z-3LR8V6",
        "outputId": "6b097d10-ff81-4434-d196-73ff8aea0b9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7233099882150197\n",
            "Recall: 0.6942084726868395\n",
            "F1-score: 0.7068180534400023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(np.array(y_test), axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEEmJTHSDmT",
        "outputId": "2af24d0e-dbad-459d-fadc-e684579ca4f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2606/2606 [==============================] - 7s 3ms/step\n",
            "Precision: 0.7637832722900731\n",
            "Recall: 0.7658885343441856\n",
            "F1-score: 0.7634821096843183\n"
          ]
        }
      ]
    }
  ]
}