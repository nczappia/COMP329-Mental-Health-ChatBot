{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjqyGvrcOKGg"
      },
      "source": [
        "# Data Loading/Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2sQ6CABOKGh"
      },
      "source": [
        "Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEWh20v5OKGh",
        "outputId": "f2436b75-7b19-425b-c511-6fcc8f2f04bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install gensim\n",
        "%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKlCKPoROKGi",
        "outputId": "87e28cba-43f8-4c4f-f0a8-c687a53c9151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import re\n",
        "import string\n",
        "\n",
        "# nltk stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "#loading the dataset\n",
        "df = pd.read_csv('emotions.csv')\n",
        "\n",
        "# tokenization and stopwords\n",
        "def clean_and_tokenize(text):\n",
        "    return [word for word in text.split() if word.lower() not in stop_words]\n",
        "\n",
        "df['tokenized'] = df['text'].apply(clean_and_tokenize)\n",
        "\n",
        "# Train Word2Vec\n",
        "model_Word2Vec = Word2Vec(sentences=df['tokenized'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to create sentence vectors by averaging word vectors\n",
        "def sentence_vector(sentence):\n",
        "    #creates word vectors. Checks if the word exists in the w2v model_Word2Vecs vocabulary\n",
        "    vectors = [model_Word2Vec.wv[word] for word in sentence if word in model_Word2Vec.wv]\n",
        "    #if if vectors is not empty put in the average vector\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    #otherwise put in zeros\n",
        "    else:\n",
        "        return np.zeros(model_Word2Vec.vector_size)\n",
        "\n",
        "X = np.array([sentence_vector(sentence) for sentence in df['tokenized']])\n",
        "\n",
        "y = df['label']\n",
        "\n",
        "#One hot encode the labels\n",
        "y_encoded = to_categorical(y, num_classes=6)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train, maxlen=20)\n",
        "X_test_padded = pad_sequences(X_test, maxlen=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462D4a_COKGj",
        "outputId": "ce6de5f1-92d5-4f27-f6df-8fb3c639091c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n"
          ]
        }
      ],
      "source": [
        "max_length = df['tokenized'].apply(lambda x: len(x)).max()\n",
        "print(max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfnghp2WOKGj",
        "outputId": "c433485a-d3d5-4d07-99ec-da3c143ccf8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.60353845,  1.0190351 ,  0.32119653,  0.47224626,  0.59523934,\n",
              "       -0.11014067,  0.15660159,  0.20875622,  0.20007655, -0.15408695,\n",
              "       -0.64697069, -0.70873183,  0.76810968, -0.51497394,  0.24410537,\n",
              "       -0.33394974,  0.03793345, -0.24877511,  0.17589469,  0.45609182,\n",
              "       -0.16143882,  0.50447434, -0.29286125,  0.32366529,  0.40783188,\n",
              "       -0.07883056, -0.56505448, -0.06840909, -0.0425799 , -0.07970779,\n",
              "        0.07295298,  0.62033862, -0.05344135, -0.05995287, -0.17092492,\n",
              "        0.32160494, -0.60756195, -0.61878973, -0.64720213,  0.04056277,\n",
              "       -0.12165699, -0.18092521,  0.46596351,  0.03574416,  1.29345989,\n",
              "       -0.4503732 ,  0.17304529, -0.93053895, -0.77637392, -0.43578172,\n",
              "        1.08976626, -0.80655909, -0.49175313,  0.08778358, -0.58111298,\n",
              "       -0.53948307,  0.53371555,  0.31081915, -0.24971655,  0.27887902,\n",
              "        0.38650855,  0.48014975,  0.07341887, -0.25780389, -0.66796941,\n",
              "       -0.07578379,  0.02085705,  0.13966917, -0.14474228,  0.70417351,\n",
              "        0.16536646,  0.21174982,  0.68682176,  0.06039782,  0.09650887,\n",
              "        0.63232464, -0.20241483, -0.34462646, -0.29074106,  0.29058498,\n",
              "       -0.1370984 , -0.12814723, -0.35877389, -0.45693675,  0.58409423,\n",
              "        1.00416636, -0.24348329,  0.48233762,  0.47682071,  0.22697687,\n",
              "        1.39372194, -0.19695902,  0.01958392,  0.00268347,  0.42953286,\n",
              "        0.36233997,  0.68016368, -0.97568542,  0.37143853, -0.02430298])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNzP8D3SOKGj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0bI5RLwOKGj"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZOr-X1COKGk",
        "outputId": "b9b52333-02cf-4bef-a219-95d6790e8cf7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1042/1043 [============================>.] - ETA: 0s - loss: 1.1615 - accuracy: 0.5669 - precision_1: 0.7034 - recall_1: 0.3802 - f1_score: 0.4936"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:2723: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  m.reset_state()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1043/1043 [==============================] - 44s 40ms/step - loss: 1.1615 - accuracy: 0.5669 - precision_1: 0.7034 - recall_1: 0.3802 - f1_score: 0.4936 - val_loss: 1.1075 - val_accuracy: 0.5841 - val_precision_1: 0.6801 - val_recall_1: 0.4597 - val_f1_score: 0.5486\n",
            "Epoch 2/10\n",
            "1043/1043 [==============================] - 42s 40ms/step - loss: 1.0059 - accuracy: 0.6260 - precision_1: 0.7278 - recall_1: 0.4935 - f1_score: 0.5882 - val_loss: 0.9736 - val_accuracy: 0.6370 - val_precision_1: 0.7308 - val_recall_1: 0.5142 - val_f1_score: 0.6036\n",
            "Epoch 3/10\n",
            "1043/1043 [==============================] - 42s 40ms/step - loss: 0.9583 - accuracy: 0.6409 - precision_1: 0.7362 - recall_1: 0.5221 - f1_score: 0.6109 - val_loss: 0.9831 - val_accuracy: 0.6369 - val_precision_1: 0.7045 - val_recall_1: 0.5519 - val_f1_score: 0.6189\n",
            "Epoch 4/10\n",
            "1043/1043 [==============================] - 41s 39ms/step - loss: 0.9291 - accuracy: 0.6530 - precision_1: 0.7416 - recall_1: 0.5408 - f1_score: 0.6254 - val_loss: 0.9791 - val_accuracy: 0.6392 - val_precision_1: 0.7024 - val_recall_1: 0.5615 - val_f1_score: 0.6241\n",
            "Epoch 5/10\n",
            "1043/1043 [==============================] - 42s 40ms/step - loss: 0.9099 - accuracy: 0.6592 - precision_1: 0.7450 - recall_1: 0.5508 - f1_score: 0.6333 - val_loss: 0.9516 - val_accuracy: 0.6428 - val_precision_1: 0.7138 - val_recall_1: 0.5536 - val_f1_score: 0.6236\n",
            "Epoch 6/10\n",
            "1043/1043 [==============================] - 42s 40ms/step - loss: 0.8954 - accuracy: 0.6634 - precision_1: 0.7486 - recall_1: 0.5596 - f1_score: 0.6405 - val_loss: 0.9086 - val_accuracy: 0.6580 - val_precision_1: 0.7370 - val_recall_1: 0.5607 - val_f1_score: 0.6369\n",
            "Epoch 7/10\n",
            "1043/1043 [==============================] - 41s 40ms/step - loss: 0.8859 - accuracy: 0.6668 - precision_1: 0.7505 - recall_1: 0.5652 - f1_score: 0.6448 - val_loss: 0.9501 - val_accuracy: 0.6425 - val_precision_1: 0.7146 - val_recall_1: 0.5496 - val_f1_score: 0.6213\n",
            "Epoch 8/10\n",
            "1043/1043 [==============================] - 45s 43ms/step - loss: 0.8755 - accuracy: 0.6702 - precision_1: 0.7529 - recall_1: 0.5703 - f1_score: 0.6490 - val_loss: 0.8863 - val_accuracy: 0.6691 - val_precision_1: 0.7660 - val_recall_1: 0.5452 - val_f1_score: 0.6370\n",
            "Epoch 9/10\n",
            "1043/1043 [==============================] - 42s 40ms/step - loss: 0.8683 - accuracy: 0.6731 - precision_1: 0.7550 - recall_1: 0.5747 - f1_score: 0.6526 - val_loss: 0.8967 - val_accuracy: 0.6587 - val_precision_1: 0.7322 - val_recall_1: 0.5689 - val_f1_score: 0.6403\n",
            "Epoch 10/10\n",
            "1043/1043 [==============================] - 42s 41ms/step - loss: 0.8620 - accuracy: 0.6748 - precision_1: 0.7559 - recall_1: 0.5771 - f1_score: 0.6545 - val_loss: 0.8776 - val_accuracy: 0.6693 - val_precision_1: 0.7457 - val_recall_1: 0.5826 - val_f1_score: 0.6541\n",
            "2606/2606 [==============================] - 20s 7ms/step - loss: 0.8727 - accuracy: 0.6717 - precision_1: 0.7495 - recall_1: 0.5844 - f1_score: 0.6567\n",
            "Test Loss: 0.8726698756217957\n",
            "Test Accuracy: 0.6716609597206116\n",
            "Precision: 0.7494884729385376\n",
            "Recall: 0.5843909978866577\n",
            "F1 Score: 0.6567224264144897\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Reshape, SimpleRNN, Dense\n",
        "\n",
        "# Custom F1 Score Metric\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + 1e-7))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "num_classes = 6\n",
        "\n",
        "rnn = Sequential()\n",
        "rnn.add(Reshape((100, 1), input_shape=(100,)))\n",
        "rnn.add(SimpleRNN(units=64))  # RNN layer\n",
        "rnn.add(Dense(units=num_classes, activation='softmax'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall(), F1Score()])\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 256\n",
        "\n",
        "# Train the model\n",
        "rnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy, precision, recall, f1 = rnn.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q96hcW2xOKGk"
      },
      "outputs": [],
      "source": [
        "rnn.save('emotions_rnn.keras')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}